# An√°lise de Desempenho do YOLOv11 para Detec√ß√£o de Copas de √Årvores

![Licen√ßa](https://img.shields.io/badge/licen%C3%A7a-MIT-blue.svg)
![Status](https://img.shields.io/badge/status-conclu%C3%ADdo-brightgreen.svg)

Este reposit√≥rio cont√©m o c√≥digo e os resultados do projeto de pesquisa para a disciplina de Introdu√ß√£o √† Intelig√™ncia Artificial, que avalia o desempenho da arquitetura YOLOv11 na tarefa de detec√ß√£o de copas de √°rvores individuais em imagens a√©reas de alta resolu√ß√£o.

---

## üìú Sum√°rio

* [Contexto do Projeto](#-contexto-do-projeto)
* [Principais Destaques](#-principais-destaques)
* [Conjunto de Dados](#-conjunto-de-dados)
* [Resultados](#-resultados)
* [Licen√ßa](#-licen√ßa)

---

## üéØ Contexto do Projeto

Este projeto foi desenvolvido como parte da avalia√ß√£o da disciplina de Introdu√ß√£o √† Intelig√™ncia Artificial da Universidade de Bras√≠lia (UnB).

O objetivo √© expandir o trabalho de benchmark de **Zamboni et al. (2021)**, que comparou 21 detectores de objetos para a detec√ß√£o de copas de √°rvores. A proposta inicial sugeria a utiliza√ß√£o do modelo **YOLO-MS**. No entanto, durante a fase de implementa√ß√£o, foram encontradas incompatibilidades t√©cnicas que dificultaram o treinamento com a base de dados fornecida.

Diante disso, tomou-se a decis√£o metodol√≥gica de pivotar para a arquitetura **YOLOv11**, uma alternativa mais moderna, bem-documentada e que n√£o havia sido avaliada no artigo de refer√™ncia, tornando esta an√°lise uma contribui√ß√£o original para a √°rea.

Foram conduzidos experimentos sistem√°ticos com as variantes **YOLOv11n (nano)** e **YOLOv11s (small)** para analisar o trade-off entre efici√™ncia e performance.

---

## ‚ú® Principais Destaques

* **Novo Estado da Arte:** O modelo YOLOv11s treinado por 50 √©pocas alcan√ßou uma **AP@0.50 de 74.9%**, superando o melhor modelo do benchmark original.
* **An√°lise de Overfitting:** O estudo revelou um claro comportamento de overfitting em treinamentos mais longos (>50 √©pocas), uma descoberta crucial para futuras implementa√ß√µes pr√°ticas.
* **Comparativo de Variantes:** An√°lise detalhada do desempenho comparativo entre as arquiteturas YOLOv11n e YOLOv11s.

---

## üå≥ Conjunto de Dados

Utilizamos o conjunto de dados p√∫blico "Individual Urban Tree Crown Detection" disponibilizado por Zamboni et al. em seu artigo. O dataset cont√©m 220 imagens a√©reas de alta resolu√ß√£o (10 cm GSD) com 3.382 copas de √°rvores anotadas.

‚û°Ô∏è **Acesse e baixe o dataset original aqui:** [pedrozamboni/individual\_urban\_tree\_crown\_detection](https://github.com/pedrozamboni/individual_urban_tree_crown_detection)

Para usar com o YOLO, as anota√ß√µes precisam ser convertidas para o formato `.txt` e o dataset deve ser estruturado conforme as instru√ß√µes na se√ß√£o [Como Usar](#-como-usar).

---

## üìä Resultados

Foram realizados 6 experimentos, testando as variantes `YOLOv11n` e `YOLOv11s` com 50, 100 e 150 √©pocas. A tabela abaixo resume os resultados de performance (AP@0.50) no conjunto de teste.

| Modelo   | √âpocas | AP@0.50 | Precis√£o | Recall |
| :------- | :----: | :-----: | :------: | :----: |
| YOLOv11n | 50     |  0.744  |  0.760   | 0.686  |
| YOLOv11n | 100    |  0.741  |  0.763   | 0.682  |
| YOLOv11n | 150    |  0.732  |  0.804   | 0.651  |
| **YOLOv11s** | **50** | **0.749** | **0.799** | **0.654** |
| YOLOv11s | 100    |  0.735  |  0.804   | 0.651  |
| YOLOv11s | 150    |  0.717  |  0.751   | 0.671  |

**Conclus√£o Principal:** O melhor resultado (**AP@0.50 de 74.9%**) foi obtido pelo **YOLOv11s com 50 √©pocas**. Treinamentos mais longos levaram a uma queda de performance, indicando um forte efeito de **overfitting**, que se tornou um ponto central da an√°lise no relat√≥rio final. Mesmo com este comportamento, o resultado de pico superou o estado da arte do benchmark original.

---

## üìù Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo `LICENSE` para mais detalhes.
